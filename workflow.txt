Workflow Breakdown:
Phase 1: Data Collection (Completed)
- What: Manually gather raw comment data from public Facebook posts of 4 target companies around their DEI announcements.
- How: Use the scripts/extract/comment_extractor.js script in the browser's developer console to save comments as raw JSON files.
    
Input: Public Facebook posts.
Output: Raw JSON files stored locally (e.g., in data/raw/<Company>/<Phase>/). Not committed.

Phase 2: Preprocessing (Mostly Complete)
Step 2a: Parse Raw JSON:
- What: Process raw JSON files to extract key fields, clean them, parse timestamps, and add metadata. PII is stripped.
- How: Run scripts/preprocess/process_comments_json.py for each company/phase.

Input: Raw JSON files from Phase 1.
Output: Individual CSV files (e.g., in data/raw/<Company>/<Phase>/comments-csv/).

Step 2b: Combine CSVs & Add Flags:
- What: Combine the individual CSV files, add the company_name, assign treatment flags (has_DEI based on company, before_DEI based on comment date vs. cutoff), and deduplicate based on comment ID.
- How: Run scripts/preprocess/combine_company_csv.py (Command: combine_raw_csvs in project.yml).

Input: Individual CSVs from Step 2a found within data/raw/<Company>/ subdirectories.
Output: data/derived/combined_comments.csv.

Step 2c: Calculate Graph Features:
- What: Add features describing the comment's position within its conversational thread (root comment ID, reply depth, sibling count, time since root).
- How: Run scripts/preprocess/graph_features.py (Command: preprocess_graph in project.yml).

Input: data/derived/combined_comments.csv.
Output: data/derived/graphed_comments.csv (This is the main dataset used for subsequent steps).

Phase 3: Text Preprocessing & Thread-aware Feature Creation
- Step 3a: Clean the comment text (preprocessing for text analytics).
- Step 3b: Build a "thread-aware" field called full_text by looking up each reply's parent (and even grandparent) comment and prepending that text to the reply, separated by an arrow, limited to at most two ancestor levels.

Input: data/derived/graphed_comments.csv.
Output: data/derived/cleaned_threaded_comments.csv.

Phase 4: Relevance Annotation & Model Training
- Step 4a: Obtain a stratified sample (by company) of 500 comments, which will be passed to Label Studio for annotation on "relevance" to DEI (0 = comment not related to DEI, 1 = comment related to DEI).
- Step 4b: Annotate in Label Studio.
- Step 4c: Fine-tune a lightweight SetFit model to label all comments (34,000) as relevant or not.
- Step 4d: Use the newly fine-tuned SetFit model to label all 34,000 comments with a new column, "relevance".

Input: data/derived/cleaned_threaded_comments.csv.
Output: data/derived/comments_with_relevance.csv.

Phase 5: Downstream Annotation & Model Training for Stance and Purchase Intention
- Step 5a: Among relevant comments (relevance = 1), obtain a stratified sample (by company) of 1,000 comments, which will be passed to Label Studio for dual-coded annotation on "stance_dei" (−1 = anti-dei, 0 = neutral, 1 = pro-dei) and "purchase_intention" (−1 = boycott, 0 = neutral, 1 = buy).
- Step 5b: Annotate in Label Studio.
- Step 5c: Fine-tune DeBERTa‑LoRA to label all comments (38,000) with dei stance and purchase intention.

Input: data/derived/comments_with_relevance.csv.
Output: data/derived/comments_with_stance_pi.csv.

Phase 6: Analysis and DiD
- Step 6a: Use the 15-day baseline to test whether the PI slopes are similar between the rollback companies and companies maintaining DEI.
- Step 6b: Once that is verified, find the effect of DEI stance on PI in "keep-DEI" companies, "rollback" companies, and the difference-in-differences (DiD) of those two effects.
- How: Run scripts/analysis/did_results.py (Placeholder: analyze).

Input: data/derived/comments_with_stance_pi.csv.
Output: Results tables/figures in results/tables/ and results/figures/.

Ongoing: Testing & Reproducibility
- What: Ensure code quality and reproducibility.
- How: Write/run unit tests (pytest tests/, placeholder test command), maintain environment.yml and project.yml.