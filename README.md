# Facebook Comment Text‑Analytics Project – README

## Project Goal  
This repository accompanies the study **“DEI Rollbacks, Brand Authenticity, and Consumer Reaction on Social Media”** (target journal: _Journal of the Academy of Marketing Science_).  
We analyze **20 000 public Facebook comments** posted during a 30‑day window around four companies’ DEI decisions to quantify:

1. **Relevance** – whether a comment addresses DEI.  
2. **Stance** – pro‑DEI, anti‑DEI, or neutral.  
3. **Purchase intent** – buy, boycott, or neutral intentions.  

---

## Compliance & Ethics Summary  
* **Manual, human‑initiated collection** only (no bots, no automated scraping).  
* **Public comments only**; no user IDs, profile links, or other PII stored.  
* **IRB status** – Protocol # _XXXX_ (Exempt Category 4 [ii]).  
* **Meta/Facebook TOS** respected: data extracted from rendered DOM; no access‑control circumvention.  
* See `/docs/Data_Statement.md` for language, time frame, provenance, and privacy safeguards.  

---

## Directory Layout  

```text
root/
│  README.md
│  LICENSE
│  CITATION.cff
│  environment.yml          ← reproducible conda/pip spec
│  project.yml              ← spaCy workflow (clean → export → train)
│
├─data/
│   ├─raw/                  ← (local only, **not** committed)
│   └─derived/
│        comments_clean.parquet
│        labels_gold.csv
│        labels_predicted.csv
│
├─docs/
│   IRB_exemption.pdf
│   Data_Statement.md
│   Methodology_Supp.pdf
│
├─scripts/
│   extract/
│      comment_extractor.js
│   process/
│      process_comments_json.py
│   annotate/
│      annotation_guidelines.md
│      label_interface.json
│   model/
│      train_setfit.py
│      train_deberta_lora.py
│   analysis/
│      did_regression.Rmd
│
├─notebooks/
│   EDA_threads.ipynb
│   Diagnostics_bias.ipynb
│
└─results/
    model_artifacts/
    figures/
    tables/
```

---

## Quick‑Start  

```bash
# 1 – Create environment
conda env create -f environment.yml
conda activate fb-text

# 2 – Run the spaCy project pipeline
spacy project run all

# 3 – Train models
python scripts/model/train_setfit.py
python scripts/model/train_deberta_lora.py

# 4 – Run causal analysis
R -e "rmarkdown::render('scripts/analysis/did_regression.Rmd')"
```

---

## Data Collection Methodology  

### Phase 1 – Manual Extraction  
1. Navigate to a public Facebook post and scroll until **all comments and replies are visible**.  
2. Open **DevTools → Console** and paste `scripts/extract/comment_extractor.js`.  
3. Copy the JSON block output and save as `MM_DD_YY_HHMMAM.json` inside `/data/raw/<Company>/`.  

### Phase 2 – JSON → CSV Processing  

```bash
python scripts/process/process_comments_json.py
# prompts for company folder & filename stem
```

### Output Columns  

| Column            | Description                                           |
|-------------------|-------------------------------------------------------|
| `company_name`    | Company slug (folder name)                            |
| `post_date`       | Post timestamp (parsed from filename)                 |
| `comment_text`    | Comment content                                       |
| `comment_date`    | Approx. comment date (derived from “2d”, “5w”)        |
| `id` / `parent_id`| Comment threading info                                |
| `reaction_count`  | Reactions shown in UI                                 |
| `comment_type`    | `initial` or `reply`                                  |

---

## Annotation & Active Learning  

* **Gold set:** 1 000 comments, dual‑coded; **Cohen’s κ ≥ 0.75**.  
* **Active learning:** entropy sampling with **`small‑text`**.  
* Guidelines & label interface: `/scripts/annotate/`.

---

## Modeling Pipeline  

| Task                 | Model                                  | Notes                                    |
|----------------------|----------------------------------------|------------------------------------------|
| **Relevance**        | SetFit (`all‑MiniLM‑L6‑v2`)            | Few‑shot, CPU‑friendly                   |
| **Stance & Purchase**| DeBERTa‑v3‑Large + LoRA (PEFT adapter) | Class‑weighted focal loss                |

---

## Causal Analysis  

Weekly **Difference‑in‑Differences** on `boycott_rate`:

```text
boycott_rate ~ rolled_back * post
              + company_FE + dow_FE
```

See `/scripts/analysis/did_regression.Rmd` for implementation.

---

## Synthetic‑Data (Contingent) Workflow  

Activated **only if** real‑data macro‑F1 falls below target.  

1. Generate **≤ 1 synthetic comment per real label** with GPT‑4o (prompt in `/scripts/model/prompts/`).  
2. Filter via self‑critique & perplexity.  
3. Retrain; keep if F1 improves ≥ 1 pp on real‑only test set.  
4. Run bias diagnostics in `/notebooks/Diagnostics_bias.ipynb`.

---

## Reproducibility & Replication  

* Every figure/table is generated by code in `/results/`.  
* A tagged GitHub release (`v1.0.0` upon acceptance) and an OSF archive provide frozen artifacts.  
* Random seeds recorded in `project.yml` and training scripts.

---

## Citation  

```bibtex
@misc{estuar2025dei,
  author       = {Estuar, Diego},
  title        = {DEI Rollbacks, Brand Authenticity, and Consumer Reaction on Facebook},
  howpublished = {\url{https://github.com/destuar/Facebook-TextAnalytics-Project}},
  year         = {2025},
  note         = {Working paper, submitted to Journal of the Academy of Marketing Science}
}
```

---

## License  

* **Code:** MIT License  
* **Derived, de‑identified datasets:** CC‑BY‑4.0  
* **Raw Facebook JSON:** _not_ redistributed to comply with Meta’s TOS.

